show.legend = F,
nudge_x = 0,
colour = "white",
hjust = c(0, -0.8),
vjust = c(0, -0.8),
segment.color = "transparent"
) +
guides(fill = guide_legend(title = "Default")) +
theme(
plot.title = element_text(
hjust = 0.5,
size = 17,
family = "serif"
),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
axis.text.x = element_blank()
)
# Credit history of defaulters
(
credit_data %>%
dplyr::select(credit_history, default) %>%
dplyr::count(credit_history, default) %>%
ggplot(aes(
x = credit_history, y = n, fill = default
)) +
geom_bar(stat = "identity",) +
guides(fill = guide_legend(title = "Default")) +
xlab("Credit History") +
ylab("Number of Obligors") +
ggtitle("Default Rate Based on Credit History") +
theme_minimal() +
theme(plot.title = element_text(
hjust = 0.5,
size = 17,
family = "serif"
),) +
scale_fill_manual(values = c("#FF5E04", "#333333"))
)
# Default rate based on credit history
CrossTable(
credit_data$credit_history,
credit_data$default,
prop.r = TRUE,
prop.c = FALSE,
prop.t = FALSE,
prop.chisq = FALSE
)
# Defaults based on loan type
credit_data %>%
dplyr::select(purpose, default) %>%
dplyr::count(purpose, default) %>%
filter(default == "yes") %>%
ggplot(aes(x = purpose, y = n, fill = purpose)) +
geom_bar(stat = "identity") +
xlab("Purpose") +
ylab("Number of Obligors") +
geom_text(aes(label = n),
vjust = 1.6,
color = "white",
size = 3.5) +
ggtitle("Loan type wise defaulters") +
scale_fill_discrete(
name = "Purpose of Loan",
labels = c(
"Business",
"Car",
"Education",
"Furniture/Appliances",
"Renovations"
)
) +
theme_minimal() +
theme(plot.title = element_text(
hjust = 0.5,
size = 26,
family = "serif"
),) +
scale_fill_manual(values = colfunc(5))
# Loan type wise default rate
CrossTable(
credit_data$purpose,
credit_data$default,
prop.r = TRUE,
prop.c = FALSE,
prop.t = FALSE,
prop.chisq = FALSE
)
# Defaults based on existing loans
credit_data %>%
dplyr::select(existing_loans_count, default) %>%
dplyr::count(existing_loans_count, default) %>%
# filter(default == "yes") %>%
ggplot(aes(x = existing_loans_count, y = n, fill = default)) +
geom_bar(stat = "identity") +
guides(fill = guide_legend(title = "Default")) +
xlab("Number of existing loans") +
ylab("Number of Obligors") +
ggtitle("Existing Loans vs Default") +
theme_minimal() +
theme(plot.title = element_text(
hjust = 0.5,
size = 17,
family = "serif"
),) +
scale_fill_manual(values = c("#FF5E04", "#333333"))
credit_data %>%
dplyr::select(job, default) %>%
dplyr::count(job, default) %>%
# filter(default == "yes") %>%
ggplot(aes(x = job, y = n, fill = default)) +
geom_bar(stat = "identity") +
guides(fill = guide_legend(title = "Default")) +
xlab("Job") +
ylab("Number of Obligors") +
ggtitle("Job vs Default") +
theme_minimal() +
theme(plot.title = element_text(
hjust = 0.5,
size = 17,
family = "serif"
),) +
scale_fill_manual(values = c("#FF5E04", "#333333"))
CrossTable(
credit_data$job,
credit_data$default,
prop.r = TRUE,
prop.c = FALSE,
prop.t = FALSE,
prop.chisq = FALSE
)
# Default vs Checking Balance
credit_data %>%
dplyr::select(checking_balance, default) %>%
dplyr::count(checking_balance, default) %>%
# filter(default == "yes") %>%
ggplot(aes(x = checking_balance, y = n, fill = default)) +
geom_bar(stat = "identity") +
guides(fill = guide_legend(title = "Default")) +
xlab("Checking Balance") +
ylab("Number of Obligors") +
ggtitle("Checking Balance vs Default") +
theme_minimal() +
theme(plot.title = element_text(
hjust = 0.5,
size = 17,
family = "serif"
),) +
scale_fill_manual(values = c("#FF5E04", "#333333"))
CrossTable(
credit_data$checking_balance,
credit_data$default,
prop.r = TRUE,
prop.c = FALSE,
prop.t = FALSE,
prop.chisq = FALSE
)
# Default vs Savings Balance
credit_data %>%
dplyr::select(savings_balance, default) %>%
dplyr::count(savings_balance, default) %>%
# filter(default == "yes") %>%
ggplot(aes(x = savings_balance, y = n, fill = default)) +
geom_bar(stat = "identity") +
guides(fill = guide_legend(title = "Default")) +
xlab("Savings Balance") +
ylab("Number of Obligors") +
ggtitle("Savings Balance vs Default") +
theme_minimal() +
theme(plot.title = element_text(
hjust = 0.5,
size = 17,
family = "serif"
),) +
scale_fill_manual(values = c("#FF5E04", "#333333"))
CrossTable(
credit_data$savings_balance,
credit_data$default,
prop.r = TRUE,
prop.c = FALSE,
prop.t = FALSE,
prop.chisq = FALSE
)
# Correlation Analysis
source("cor_check.R")
correlation <-
mixed_assoc(credit_data, adjust_cramersv_bias = F)[c("x", "y", "assoc")]
cor_plot_df <- correlation %>% spread(y, assoc)
colnames(cor_plot_df) <-
c(
"x",
"Age",
"Amt",
"ChBal",
"CrHis",
"Default",
"Dep",
"Emp_Dur",
"ExLoan",
"House",
"Job",
"MLD",
"OthCr",
"%Inc",
"Ph",
"Purp",
"SvBal",
"YAR"
)
cor_plot_df %>%
column_to_rownames("x") %>%
as.matrix() %>%
corrplot(
number.cex = 0.7,
tl.cex = 0.9,
insig = "blank",
type = "lower",
method = "number",
bg = "#333333",
diag = T,
tl.col = "black",
col = colorRampPalette(c("white", "#FF5E04"))(200),
tl.srt = 45
)
cor_plot_df %>%
column_to_rownames("x") %>%
filter(Default < 0.1) %>%
dplyr::select(Default)
# Doing a train-test split for model creation
set.seed(179)
samp <- createDataPartition(credit_data$default, p = 0.70)
training <- credit_data[unlist(samp),]
testing <- credit_data[-unlist(samp),]
prop.table(table(training$default))
prop.table(table(testing$default))
logistic1 <- glm(default ~ ., data = credit_data, family = binomial)
summary(logistic1)
car::vif(logistic1)
anova(logistic1, test = "Chisq")
# Removing insignificant variables job, years_at_residence, existing_loans_count and dependents.
logistic2 <-
glm(
default ~ . - job - dependants - years_at_residence - existing_loans_count,
data = training,
family = binomial
)
summary(logistic2)
anova(logistic2, test = "Chisq")
vif(logistic2)
logistic3 <-
glm(
default ~ . - job - dependants - years_at_residence -
existing_loans_count - months_loan_duration,
data = training,
family = binomial
)
summary(logistic3)
vif(logistic3) # No indication of multi-collinearity.
anova(logistic3, test = "Chisq")
lrtest(logistic3, logistic2)
# Making predictions and checking model fit.
pred_check_in <- 0
pred_check_out <- 0
val <- 0
val1 <- 0
insamp_predict <-
predict.glm(logistic3, newdata = training, type = "response")
insamp_predict <- ifelse(insamp_predict > 0.57, "yes", "no")
insamp_predict <- as.factor(insamp_predict)
caret::confusionMatrix(training$default, insamp_predict)
outsamp_predict <-
predict.glm(logistic3, newdata = testing, type = "response")
outsamp_predict <- ifelse(outsamp_predict > 0.57, "yes", "no")
outsamp_predict <- as.factor(outsamp_predict)
caret::confusionMatrix(testing$default, outsamp_predict)
pR2(logistic3)
somersD(factor(
training$default,
levels = c("no", "yes"),
labels = c(0, 1)
),
fitted(logistic3))
hoslem.test(training$default, logistic3$fitted.values)
# Testing the linearity assumption.
probs <- fitted(logistic3)
numeric_data <- training %>% dplyr::select_if(is.numeric)
predictors <- colnames(numeric_data)
numeric_data <- numeric_data %>%
mutate(logit = log(probs / (1 - probs))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
ggplot(numeric_data, aes(logit, predictor.value)) +
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap( ~ predictors, scales = "free_y")
# K-fold Cross Validation:
train_control <- trainControl(method = "cv", number = 10)
model4 <-
train(
default ~ checking_balance + credit_history + purpose + amount +
savings_balance + employment_duration + percent_of_income + age +
other_credit + housing + phone,
data = training,
method = "glm",
family = binomial,
trControl = train_control
)
model4
predict_kcv <- predict(model4, testing)
roc_predict_kcv <- ifelse(predict_kcv == "no", 0, 1)
roc_predict_test <- ifelse(testing$default == "no", 0, 1)
caret::confusionMatrix(predict_kcv, testing$default)
plotROC(roc_predict_test, roc_predict_kcv)
# Checking which seed gives highest accuracy and McFaddens R2.
seed <- numeric()
r2 <- numeric()
for (i in 1:1000) {
set.seed(i)
samp <- createDataPartition(credit_data$default, p = 0.70)
training <- credit_data[unlist(samp),]
logistic3 <-
glm(
default ~ . - job - dependants - years_at_residence
- existing_loans_count - months_loan_duration,
data = training,
family = binomial
)
r2[i] <- pR2(logistic3)["McFadden"]
seed[i] <- i
}
which.max(r2)
max(r2)
set.seed(53)
samp <- createDataPartition(credit_data$default, p = 0.70)
training <- credit_data[unlist(samp),]
testing <- credit_data[-unlist(samp),]
tree <-
rpart::rpart(default ~ .,
data = training,
control = rpart.control(cp = 0.01))
insample_tree <- predict(tree, training, type = "class")
outsample_tree <- predict(tree, testing, type = "class")
caret::confusionMatrix(training$default, insample_tree)
caret::confusionMatrix(testing$default, outsample_tree)
rpart::printcp(tree)
rpart::plotcp(tree)
caret::varImp(tree)
fancyRpartPlot(tree)
roc_predict_tree <- ifelse(outsample_tree == "no", 0, 1)
roc_predict_test <- ifelse(testing$default == "no", 0, 1)
roc_predict_train <- ifelse(training$default == "no", 0, 1)
caret::confusionMatrix(outsample_tree, testing$default)
InformationValue::plotROC(roc_predict_test, roc_predict_tree)
vm <- caret::varImp(tree)
ggplot(vm, aes(x = reorder(rownames(vm), Overall), y = Overall)) +
geom_point(color = "#333333",
size = 4,
alpha = 0.8) +
geom_segment(aes(
x = rownames(vm),
xend = rownames(vm),
y = 0,
yend = Overall
),
color = "#FF5E04") +
xlab("Variable") +
ylab("Overall Importance") +
theme_minimal() +
ggtitle("Variable Importance Plot (Decision Tree)") +
coord_flip() +
theme(plot.title = element_text(
hjust = 0.5,
family = "serif",
size = 17
))
roc_predict_tree_in <- ifelse(insample_tree == "no", 0, 1)
InformationValue::plotROC(roc_predict_train, roc_predict_tree_in)
roc_predict_tree <- ifelse(outsample_tree == "no", 0, 1)
InformationValue::plotROC(roc_predict_test, roc_predict_tree)
seed <- numeric()
acc <- numeric()
# Random Forest
control_forest <- trainControl(method = "cv", number = 10)
seed <- 8
metric <- "Accuracy"
set.seed(seed)
mtry <- sqrt(ncol(credit_data))
tunegrid <- expand.grid(.mtry = mtry)
rf_default <-
train(
default ~ .,
data = training,
method = "rf",
metric = metric,
tuneGrid = tunegrid,
trControl = control_forest
)
forest_insamp <- predict(rf_default, training)
forest_predict <- predict(rf_default, testing)
caret::confusionMatrix(forest_insamp, training$default)
caret::confusionMatrix(forest_predict, testing$default)
plotROC(roc_predict_train, ifelse(forest_insamp == "no", 0, 1))
plotROC(roc_predict_test, ifelse(forest_predict == "no", 0, 1))
vmf <- caret::varImp(rf_default)
ggplot(vmf$importance, aes(x = reorder(rownames(vmf$importance), Overall), y = Overall)) +
geom_point(color = "#333333",
size = 4,
alpha = 0.8) +
geom_segment(aes(
x = rownames(vmf$importance),
xend = rownames(vmf$importance),
y = 0,
yend = Overall
),
color = "#FF5E04") +
xlab("Variable") +
ylab("Overall Importance") +
theme_minimal() +
ggtitle("Variable Importance Plot (Random Forest)") +
coord_flip() +
theme(plot.title = element_text(
hjust = 10,
family = "serif",
size = 17,
color = "black"
))
# Gradient Boosting
set.seed(179)
samp <- createDataPartition(credit_data$default, p = 0.70)
training <- credit_data[unlist(samp),]
testing <- credit_data[-unlist(samp),]
labels <- training$default
labels_ts <- testing$default
boost_tr <-
model.matrix( ~ . + 0, data = training %>% dplyr::select(-c(default)))
boost_ts <-
model.matrix( ~ . + 0, data = testing %>% dplyr::select(-c(default)))
labels <- as.numeric(labels) - 1
labels_ts <- as.numeric(labels_ts) - 1
dtrain <- xgb.DMatrix(data = boost_tr, label = labels)
dtest <- xgb.DMatrix(data = boost_ts, label = labels_ts)
params <- list(
booster = "gbtree",
objective = "binary:logistic",
eta = 0.21,
gamma = 0,
max_depth = 6,
min_child_weight = 1,
subsample = 1,
colsample_bytree = 1
)
xgbcv <- xgb.cv(
params = params,
data = dtrain,
nrounds = 1000,
nfold = 10,
showsd = T,
stratified = T,
print_every_n = 1,
maximize = F,
eval_metric = "error",
early_stopping_rounds = 200,
verbose = F
)
xgbcv$best_iteration
xgbcv$best_ntreelimit
xgb <- xgb.train(
params = params,
data = dtrain,
nrounds = 162,
watchlist = list(val = dtest, train = dtrain),
print_every_n = 1,
early_stopping_rounds = 10,
maximize = F,
eval_metric = "error",
n_tree = 162
)
predict_xgb_tr <- predict(xgb, dtrain)
predict_xgb_tr <- ifelse(predict_xgb_tr > 0.5, 1, 0)
predict_xgb_tr <- predict_xgb_tr + 1
predict_xgb_tr <-
factor(predict_xgb_tr,
levels = c(1, 2),
labels = c("no", "yes"))
caret::confusionMatrix(predict_xgb_tr, training$default)
plotROC(ifelse(training$default == "no", 0, 1),
ifelse(predict_xgb_tr == "no", 0, 1))
predict_xgb <- predict(xgb, dtest)
predict_xgb <- ifelse(predict_xgb > 0.5, 1, 0)
predict_xgb <- predict_xgb + 1
predict_xgb <-
factor(predict_xgb,
levels = c(1, 2),
labels = c("no", "yes"))
caret::confusionMatrix(predict_xgb, testing$default)
plotROC(ifelse(testing$default == "no", 0, 1),
ifelse(predict_xgb == "no", 0, 1))
xgb_imp <- xgb.importance(colnames(boost_tr), model = xgb)
(gg <-
xgb.ggplot.importance(xgb_imp, measure = "Frequency", top_n = 12))
gg + ylab("Frequency") +
ggtitle("Feature Importance") +
guides(fill = FALSE, color = FALSE) +
theme_minimal() +
theme(plot.title = element_text(
hjust = 0.5,
size = 17,
family = "serif"
),) +
scale_fill_manual(values = c("#FF5E04", "#333333"))
